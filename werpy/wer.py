# SPDX-FileCopyrightText: 2023 Analytics in Motion <https://www.analyticsinmotion.com>
# SPDX-License-Identifier: BSD-3-Clause

"""
This module provides a function for calculating the Word Error Rate (WER) between a reference text and a hypothesis 
text. The WER is calculated as the number of edits (insertions, deletions, and substitutions) needed to transform 
the hypothesis text into the reference text, divided by the number of words in the reference text.

This module defines the following function:
    - wer(reference, hypothesis): Calculate the WER between a reference text and a hypothesis text.
"""

import numpy as np
from .errorhandler import error_handler


def wer(reference, hypothesis) -> float | np.float64 | None:
    """
    This function will calculate the overall Word Error Rate for the entire reference and hypothesis texts 
    (i.e., the full corpus).

    Parameters
    ----------
    reference : str, list or numpy array
        The ground truth transcription of a recorded speech or the expected output of a live speech.
    hypothesis : str, list or numpy array
        The text generated by a speech-to-text algorithm/system which will be compared to the reference text.

    Raises
    ------
    ValueError
        if the two input parameters do not contain the same amount of elements.
    AttributeError
        if input text is not a string, list or np.ndarray data type.
    ZeroDivisionError
        if input in reference is blank or both reference and hypothesis are empty.

    Returns
    -------
    float, np.float64, or None
        This function will return a single Word Error Rate as a float or NumPy float64, which is calculated as the 
        number of edits (insertions, deletions, and substitutions) divided by the number of words in the reference 
        text. If an exception occurs (e.g., invalid input), the function will return None.

    Examples
    --------
    >>> wer_example_1 = wer('i love cold pizza', 'i love pizza')
    >>> print(wer_example_1)
    0.25

    >>> ref = ['i love cold pizza','the sugar bear character was popular']
    >>> hyp = ['i love pizza','the sugar bare character was popular']
    >>> wer_example_2 = wer(ref, hyp)
    >>> print(wer_example_2)
    0.2
    """
    try:
        word_error_rate_breakdown = error_handler(reference, hypothesis)
    except (ValueError, AttributeError, ZeroDivisionError) as err:
        print(f"{type(err).__name__}: {str(err)}")
        return None

    b = word_error_rate_breakdown

    # Unwrap 0-D container
    if isinstance(b, np.ndarray) and b.ndim == 0:
        b = b.item()

    if isinstance(b, np.ndarray):
        if b.ndim == 2:
            # True 2-D numeric batch
            t = b.T
            wer_result = float(np.sum(t[1]) / np.sum(t[2]))

        elif b.ndim == 1:
            # Could be either:
            # (a) single example row vector, or
            # (b) object array of per-example vectors
            first = b[0] if b.size else None

            if isinstance(first, (np.ndarray, list, tuple)):
                # Batch stored as 1-D object array of per-example vectors (ragged fields exist)
                total_ld = 0.0
                total_m = 0.0
                for r in b:
                    rr = r.tolist() if isinstance(r, np.ndarray) else r
                    total_ld += float(rr[1])
                    total_m += float(rr[2])
                wer_result = float(total_ld / total_m) if total_m else 0.0
            else:
                # Single example vector
                wer_result = float(b[0])

        else:
            raise ValueError(f"Unexpected metrics output ndim: {b.ndim}")

    else:
        # Non-numpy fallback (assume [wer, ld, m, ...])
        wer_result = float(b[0])

    return wer_result
