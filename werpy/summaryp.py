"""
This module provides a summary function to display a complete breakdown of the calculated results, returned in a 
DataFrame. It differs from the summary function in that it also calculates a weighted WER and returns it in the
dataframe.

This module defines the following function:
    - summaryp(reference, hypothesis)
"""

import numpy as np
import pandas as pd
from .errorhandler import error_handler


def summaryp(reference, hypothesis, insertions_weight=1, deletions_weight=1, substitutions_weight=1):
    """
    This function provides a comprehensive breakdown of the calculated results including the WER, weighted
    WER, Levenshtein Distance and all the insertion, deletion and substitution errors.

    Parameters
    ----------
    reference : str, list or numpy array
        The ground truth transcription of a recorded speech or the expected output of a live speech.
    hypothesis : str, list or numpy array
        The text generated by a speech-to-text algorithm/system which will be compared to the reference text.
    insertions_weight: int or float, optional
        The weight multiplier for an insertion error
    deletions_weight: int or float, optional
        The weight multiplier for a deletion error
    substitutions_weight: int or float, optional
        The weight multiplier for a substitution error

    Raises
    ------
    ValueError
        if the two input parameters do not contain the same amount of elements.
    AttributeError
        if input text is not a string, list or np.ndarray data type.

    Returns
    -------
    pandas.core.frame.DataFrame
        Returns a dataframe containing the following ten columns:
            wer - The Word Error Rate
            werp - The weighted Word Error Rate
            ld - The Levenshtein distance
            m - The number of words in the reference sequence
            insertions - count of words that are present in the hypothesis sequence but not in the reference
            deletions - count of words that are present in the reference sequence but not in the hypothesis
            substitutions - count of words needing to be transformed so the hypothesis matches the reference
            inserted_words - list of inserted words
            deleted_words - list of deleted words
            substituted_words - list of substitutions. Each substitution will be shown as a tuple with the reference
            word and the hypothesis word. For example: [(cited, sighted), (abnormally, normally)]
    """
    try:
        word_error_rate_breakdown = error_handler(reference, hypothesis)
    except (ValueError, AttributeError) as err:
        print(f"{type(err).__name__}: {str(err)}")
        return None
    if isinstance(word_error_rate_breakdown[0], np.ndarray):
        word_error_rate_breakdown = word_error_rate_breakdown.tolist()
        transform_word_error_rate_breakdown = np.transpose(word_error_rate_breakdown)
        weighted_insertions = transform_word_error_rate_breakdown[3] * insertions_weight
        weighted_deletions = transform_word_error_rate_breakdown[4] * deletions_weight
        weighted_substitutions = transform_word_error_rate_breakdown[5] * substitutions_weight
        m = transform_word_error_rate_breakdown[2]
        weighted_errors = sum((weighted_insertions, weighted_deletions, weighted_substitutions))
        werps_result = (weighted_errors / m).tolist()
    else:
        word_error_rate_breakdown = [word_error_rate_breakdown.tolist()]
        weighted_insertions = word_error_rate_breakdown[0][3] * insertions_weight
        weighted_deletions = word_error_rate_breakdown[0][4] * deletions_weight
        weighted_substitutions = word_error_rate_breakdown[0][5] * substitutions_weight
        m = word_error_rate_breakdown[0][2]
        weighted_errors = sum((weighted_insertions, weighted_deletions, weighted_substitutions))
        werps_result = weighted_errors / m

    columns = ['wer', 'ld', 'm', 'insertions', 'deletions', 'substitutions', 'inserted_words', 'deleted_words',
                   'substituted_words']    
    df = pd.DataFrame(word_error_rate_breakdown, columns=columns)
    df['werp'] = werps_result
    df = df[['wer', 'werp', 'ld', 'm', 'insertions', 'deletions', 'substitutions', 'inserted_words'
             , 'deleted_words', 'substituted_words']]
    return df
