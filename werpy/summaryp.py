# SPDX-FileCopyrightText: 2023 Analytics in Motion <https://www.analyticsinmotion.com>
# SPDX-License-Identifier: BSD-3-Clause

"""
This module provides a summary function to display a complete breakdown of the calculated results, returned in a 
DataFrame. It differs from the summary function in that it also calculates a weighted WER and returns it in the
dataframe.

This module defines the following function:
    - summaryp(reference, hypothesis)
"""

import numpy as np
import pandas as pd
from .errorhandler import error_handler


def summaryp(
    reference,
    hypothesis,
    insertions_weight=1,
    deletions_weight=1,
    substitutions_weight=1,
):
    """
    This function provides a comprehensive breakdown of the calculated results including the WER, weighted
    WER, Levenshtein Distance and all the insertion, deletion and substitution errors.

    Parameters
    ----------
    reference : str, list or numpy array
        The ground truth transcription of a recorded speech or the expected output of a live speech.
    hypothesis : str, list or numpy array
        The text generated by a speech-to-text algorithm/system which will be compared to the reference text.
    insertions_weight: int or float, optional
        The weight multiplier for an insertion error
    deletions_weight: int or float, optional
        The weight multiplier for a deletion error
    substitutions_weight: int or float, optional
        The weight multiplier for a substitution error

    Raises
    ------
    ValueError
        if the two input parameters do not contain the same amount of elements.
    AttributeError
        if input text is not a string, list or np.ndarray data type.
    ZeroDivisionError
        if input in reference is blank or both reference and hypothesis are empty.

    Returns
    -------
    pandas.core.frame.DataFrame
        Returns a dataframe containing the following ten columns:
            wer - The Word Error Rate
            werp - The weighted Word Error Rate
            ld - The Levenshtein distance
            m - The number of words in the reference sequence
            insertions - count of words that are present in the hypothesis sequence but not in the reference
            deletions - count of words that are present in the reference sequence but not in the hypothesis
            substitutions - count of words needing to be transformed so the hypothesis matches the reference
            inserted_words - list of inserted words
            deleted_words - list of deleted words
            substituted_words - list of substitutions. Each substitution will be shown as a tuple with the reference
            word and the hypothesis word. For example: [(cited, sighted), (abnormally, normally)]
    """
    try:
        word_error_rate_breakdown = error_handler(reference, hypothesis)
    except (ValueError, AttributeError, ZeroDivisionError) as err:
        print(f"{type(err).__name__}: {str(err)}")
        return None
    if isinstance(word_error_rate_breakdown[0], np.ndarray):
        word_error_rate_breakdown = word_error_rate_breakdown.tolist()
        transform_word_error_rate_breakdown = np.transpose(word_error_rate_breakdown)
        weighted_insertions = transform_word_error_rate_breakdown[3] * insertions_weight
        weighted_deletions = transform_word_error_rate_breakdown[4] * deletions_weight
        weighted_substitutions = (
            transform_word_error_rate_breakdown[5] * substitutions_weight
        )
        m = transform_word_error_rate_breakdown[2]
        weighted_errors = sum(
            (weighted_insertions, weighted_deletions, weighted_substitutions)
        )
        werps_result = (weighted_errors / m).tolist()
    else:
        word_error_rate_breakdown = [word_error_rate_breakdown.tolist()]
        weighted_insertions = word_error_rate_breakdown[0][3] * insertions_weight
        weighted_deletions = word_error_rate_breakdown[0][4] * deletions_weight
        weighted_substitutions = word_error_rate_breakdown[0][5] * substitutions_weight
        m = word_error_rate_breakdown[0][2]
        weighted_errors = sum(
            (weighted_insertions, weighted_deletions, weighted_substitutions)
        )
        werps_result = weighted_errors / m

    columns = [
        "wer",
        "ld",
        "m",
        "insertions",
        "deletions",
        "substitutions",
        "inserted_words",
        "deleted_words",
        "substituted_words",
    ]
    df = pd.DataFrame(word_error_rate_breakdown, columns=columns)
    df["werp"] = werps_result
    df = df[
        [
            "wer",
            "werp",
            "ld",
            "m",
            "insertions",
            "deletions",
            "substitutions",
            "inserted_words",
            "deleted_words",
            "substituted_words",
        ]
    ]
    return df
