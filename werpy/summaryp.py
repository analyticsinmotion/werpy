# SPDX-FileCopyrightText: 2023 Analytics in Motion <https://www.analyticsinmotion.com>
# SPDX-License-Identifier: BSD-3-Clause

"""
This module provides a summary function to display a complete breakdown of the calculated results, returned in a 
DataFrame. It differs from the summary function in that it also calculates a weighted WER and returns it in the
dataframe.

This module defines the following function:
    - summaryp(reference, hypothesis)
"""

import numpy as np
import pandas as pd
from .errorhandler import error_handler


def summaryp(
    reference,
    hypothesis,
    insertions_weight=1,
    deletions_weight=1,
    substitutions_weight=1,
):
    """
    This function provides a comprehensive breakdown of the calculated results including the WER, weighted
    WER, Levenshtein Distance and all the insertion, deletion and substitution errors.

    Parameters
    ----------
    reference : str, list or numpy array
        The ground truth transcription of a recorded speech or the expected output of a live speech.
    hypothesis : str, list or numpy array
        The text generated by a speech-to-text algorithm/system which will be compared to the reference text.
    insertions_weight: int or float, optional
        The weight multiplier for an insertion error
    deletions_weight: int or float, optional
        The weight multiplier for a deletion error
    substitutions_weight: int or float, optional
        The weight multiplier for a substitution error

    Raises
    ------
    ValueError
        if the two input parameters do not contain the same amount of elements.
    AttributeError
        if input text is not a string, list or np.ndarray data type.
    ZeroDivisionError
        if input in reference is blank or both reference and hypothesis are empty.

    Returns
    -------
    pandas.core.frame.DataFrame
        Returns a dataframe containing the following ten columns:
            wer - The Word Error Rate
            werp - The weighted Word Error Rate
            ld - The Levenshtein distance
            m - The number of words in the reference sequence
            insertions - count of words that are present in the hypothesis sequence but not in the reference
            deletions - count of words that are present in the reference sequence but not in the hypothesis
            substitutions - count of words needing to be transformed so the hypothesis matches the reference
            inserted_words - list of inserted words
            deleted_words - list of deleted words
            substituted_words - list of substitutions. Each substitution will be shown as a tuple with the reference
            word and the hypothesis word. For example: [(cited, sighted), (abnormally, normally)]
    """
    try:
        word_error_rate_breakdown = error_handler(reference, hypothesis)
    except (ValueError, AttributeError, ZeroDivisionError) as err:
        print(f"{type(err).__name__}: {str(err)}")
        return None

    b = word_error_rate_breakdown

    # Unwrap 0-D container
    if isinstance(b, np.ndarray) and b.ndim == 0:
        b = b.item()

    if isinstance(b, np.ndarray):
        if b.ndim == 2:
            # True 2-D numeric batch
            word_error_rate_breakdown = b.tolist()
            t = b.T
            weighted_insertions = t[3] * insertions_weight
            weighted_deletions = t[4] * deletions_weight
            weighted_substitutions = t[5] * substitutions_weight
            m = t[2]
            weighted_errors = weighted_insertions + weighted_deletions + weighted_substitutions
            werps_result = (weighted_errors / m).tolist()

        elif b.ndim == 1:
            # Could be either:
            # (a) single example row vector, or
            # (b) object array of per-example vectors
            first = b[0] if b.size else None

            if isinstance(first, (np.ndarray, list, tuple)):
                # Batch stored as 1-D object array of per-example vectors (ragged fields exist)
                word_error_rate_breakdown = []
                werps_result = []
                for r in b:
                    rr = r.tolist() if isinstance(r, np.ndarray) else r
                    word_error_rate_breakdown.append(rr)
                    w_ins = float(rr[3]) * insertions_weight
                    w_del = float(rr[4]) * deletions_weight
                    w_sub = float(rr[5]) * substitutions_weight
                    m_val = float(rr[2])
                    weighted_wer = (w_ins + w_del + w_sub) / m_val if m_val else 0.0
                    werps_result.append(weighted_wer)
            else:
                # Single example vector - wrap in list for DataFrame
                word_error_rate_breakdown = [b.tolist()]
                weighted_insertions = b[3] * insertions_weight
                weighted_deletions = b[4] * deletions_weight
                weighted_substitutions = b[5] * substitutions_weight
                m = b[2]
                weighted_errors = weighted_insertions + weighted_deletions + weighted_substitutions
                werps_result = float(weighted_errors / m) if m else 0.0

        else:
            raise ValueError(f"Unexpected metrics output ndim: {b.ndim}")

    else:
        # Non-numpy fallback (assume [wer, ld, m, ...])
        word_error_rate_breakdown = [b.tolist() if hasattr(b, 'tolist') else b]
        weighted_insertions = b[3] * insertions_weight
        weighted_deletions = b[4] * deletions_weight
        weighted_substitutions = b[5] * substitutions_weight
        m = b[2]
        weighted_errors = weighted_insertions + weighted_deletions + weighted_substitutions
        werps_result = float(weighted_errors / m) if m else 0.0

    columns = [
        "wer",
        "ld",
        "m",
        "insertions",
        "deletions",
        "substitutions",
        "inserted_words",
        "deleted_words",
        "substituted_words",
    ]
    df = pd.DataFrame(word_error_rate_breakdown, columns=columns)
    df["werp"] = werps_result
    df = df[
        [
            "wer",
            "werp",
            "ld",
            "m",
            "insertions",
            "deletions",
            "substitutions",
            "inserted_words",
            "deleted_words",
            "substituted_words",
        ]
    ]
    return df
