# SPDX-FileCopyrightText: 2023 Analytics in Motion <https://www.analyticsinmotion.com>
# SPDX-License-Identifier: BSD-3-Clause

"""
This module provides a summary function to display a complete breakdown of the calculated results, returned in a 
DataFrame. It differs from the summary function in that it also calculates a weighted WER and returns it in the
dataframe.

This module defines the following function:
    - summaryp(reference, hypothesis)
"""

import numpy as np
import pandas as pd
from .errorhandler import error_handler
from .metrics import metrics


def summaryp(
    reference,
    hypothesis,
    insertions_weight=1,
    deletions_weight=1,
    substitutions_weight=1,
):
    """
    This function provides a comprehensive breakdown of the calculated results including the WER, weighted
    WER, Levenshtein Distance and all the insertion, deletion and substitution errors.

    Parameters
    ----------
    reference : str, list or numpy array
        The ground truth transcription of a recorded speech or the expected output of a live speech.
    hypothesis : str, list or numpy array
        The text generated by a speech-to-text algorithm/system which will be compared to the reference text.
    insertions_weight: int or float, optional
        The weight multiplier for an insertion error
    deletions_weight: int or float, optional
        The weight multiplier for a deletion error
    substitutions_weight: int or float, optional
        The weight multiplier for a substitution error

    Raises
    ------
    ValueError
        if the two input parameters do not contain the same amount of elements.
    AttributeError
        if input text is not a string, list or np.ndarray data type.
    ZeroDivisionError
        if input in reference is blank or both reference and hypothesis are empty.

    Returns
    -------
    pandas.core.frame.DataFrame
        Returns a dataframe containing the following ten columns:
            wer - The Word Error Rate
            werp - The weighted Word Error Rate
            ld - The Levenshtein distance
            m - The number of words in the reference sequence
            insertions - count of words that are present in the hypothesis sequence but not in the reference
            deletions - count of words that are present in the reference sequence but not in the hypothesis
            substitutions - count of words needing to be transformed so the hypothesis matches the reference
            inserted_words - list of inserted words
            deleted_words - list of deleted words
            substituted_words - list of substitutions. Each substitution will be shown as a tuple with the reference
            word and the hypothesis word. For example: [(cited, sighted), (abnormally, normally)]
    """
    try:
        error_handler(reference, hypothesis)
    except (ValueError, AttributeError, ZeroDivisionError) as err:
        print(f"{type(err).__name__}: {str(err)}")
        return None

    result = metrics(reference, hypothesis)

    # Batch rows (n, 9)
    if isinstance(result, np.ndarray) and result.ndim == 2:
        word_error_rate_breakdown = result.tolist()
        weighted_insertions = result[:, 3] * insertions_weight
        weighted_deletions = result[:, 4] * deletions_weight
        weighted_substitutions = result[:, 5] * substitutions_weight
        m = result[:, 2]
        weighted_errors = weighted_insertions + weighted_deletions + weighted_substitutions
        werps_result = (weighted_errors / m).tolist()
    else:
        # Single row - wrap in list for DataFrame
        if isinstance(result, np.ndarray) and getattr(result, "ndim", 0) == 0:
            result = result.item()
        word_error_rate_breakdown = [result.tolist() if hasattr(result, 'tolist') else list(result)]
        weighted_insertions = result[3] * insertions_weight
        weighted_deletions = result[4] * deletions_weight
        weighted_substitutions = result[5] * substitutions_weight
        m = result[2]
        weighted_errors = weighted_insertions + weighted_deletions + weighted_substitutions
        werps_result = float(weighted_errors / m) if m else 0.0

    columns = [
        "wer",
        "ld",
        "m",
        "insertions",
        "deletions",
        "substitutions",
        "inserted_words",
        "deleted_words",
        "substituted_words",
    ]
    df = pd.DataFrame(word_error_rate_breakdown, columns=columns)
    df["werp"] = werps_result
    df = df[
        [
            "wer",
            "werp",
            "ld",
            "m",
            "insertions",
            "deletions",
            "substitutions",
            "inserted_words",
            "deleted_words",
            "substituted_words",
        ]
    ]
    return df
